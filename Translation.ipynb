{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# ignore some Keras warnings regarding deprecations and model saving \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import pickle, numpy as np\n",
    "from random import Random\n",
    "from helpers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples =10000 # Number of samples to train on.\n",
    "# Path to the datatxt file on disk.\n",
    "data_path = 'fra.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 10000 selected phrases\n"
     ]
    }
   ],
   "source": [
    "all_input_phrases, all_target_phrases = read_data(data_path)\n",
    "# do some text pre-processing\n",
    "all_input_phrases = text_preprocess(all_input_phrases)\n",
    "all_target_phrases = text_preprocess(all_target_phrases)\n",
    "# add the delimiters signifying the beginning and end of a sequence\n",
    "all_target_phrases = wrap_with_delims(all_target_phrases)\n",
    "\n",
    "# keep only `num_samples` examples. \n",
    "# Note: we're starting from the 2nd example, its not important\n",
    "input_phrases, target_phrases = all_input_phrases[:num_samples], all_target_phrases[:num_samples]\n",
    "# Wrap the target phrases with delimiters signifying the start end end of the sequence\n",
    "\n",
    "print(\"Training on %d selected phrases\" % len(input_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('go', '\\tva !\\n'),\n",
       " ('run!', '\\tcours!\\n'),\n",
       " ('run!', '\\tcourez!\\n'),\n",
       " ('fire!', '\\tau feu !\\n'),\n",
       " ('help!', \"\\t√† l'aide!\\n\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(input_phrases[:5], target_phrases[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique input tokens: 63\n",
      "Number of unique output tokens: 83\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 58\n"
     ]
    }
   ],
   "source": [
    "# build the token index on all available phrases\n",
    "input_token_index = token_index(all_input_phrases)\n",
    "target_token_index = token_index(all_target_phrases)\n",
    "num_encoder_tokens = len(input_token_index)\n",
    "num_decoder_tokens = len(target_token_index)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_phrases])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_phrases])\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(num_encoder_tokens, num_decoder_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_inputs')\n",
    "    encoder = LSTM(latent_dim, return_state=True, name='encoder')\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_inputs')\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, \n",
    "                        name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax', \n",
    "                          name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # Next: inference mode (sampling).\n",
    "    # Here's the drill:\n",
    "    # 1) encode input and retrieve initial decoder state\n",
    "    # 2) run one step of decoder with this initial state\n",
    "    # and a \"start of sequence\" token as target.\n",
    "    # Output will be the next target token\n",
    "    # 3) Repeat with the current target token and current states\n",
    "\n",
    "    # Define sampling models\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,), name='decoder_input_h')\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,), name='decoder_input_c')\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, encoder_model, decoder_model = models(num_encoder_tokens, num_decoder_tokens, latent_dim)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.8979 - val_loss: 0.9907\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.7376 - val_loss: 0.8269\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.6355 - val_loss: 0.7563\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.5784 - val_loss: 0.7149\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.5397 - val_loss: 0.6668\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.5049 - val_loss: 0.6502\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.4766 - val_loss: 0.6151\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.4528 - val_loss: 0.5963\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.4319 - val_loss: 0.5801\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.4156 - val_loss: 0.5658\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3981 - val_loss: 0.5544\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3836 - val_loss: 0.5404\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3693 - val_loss: 0.5337\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3562 - val_loss: 0.5289\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3443 - val_loss: 0.5205\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3326 - val_loss: 0.5200\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3218 - val_loss: 0.5143\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3117 - val_loss: 0.5109\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.3022 - val_loss: 0.5172\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2930 - val_loss: 0.5083\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2839 - val_loss: 0.5071\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2758 - val_loss: 0.5082\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2674 - val_loss: 0.5094\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2601 - val_loss: 0.5068\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2527 - val_loss: 0.5123\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2457 - val_loss: 0.5127\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2391 - val_loss: 0.5118\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2327 - val_loss: 0.5160\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2263 - val_loss: 0.5212\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2203 - val_loss: 0.5237\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2146 - val_loss: 0.5261\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2091 - val_loss: 0.5312\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.2040 - val_loss: 0.5340\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1988 - val_loss: 0.5372\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1933 - val_loss: 0.5433\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1893 - val_loss: 0.5527\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1844 - val_loss: 0.5534\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1801 - val_loss: 0.5545\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1758 - val_loss: 0.5583\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1718 - val_loss: 0.5730\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1682 - val_loss: 0.5645\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1640 - val_loss: 0.5726\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1604 - val_loss: 0.5748\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1568 - val_loss: 0.5772\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1531 - val_loss: 0.5845\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1499 - val_loss: 0.5990\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1465 - val_loss: 0.5979\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1435 - val_loss: 0.6012\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1404 - val_loss: 0.6007\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1374 - val_loss: 0.6072\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1349 - val_loss: 0.6180\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1321 - val_loss: 0.6181\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1294 - val_loss: 0.6287\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1269 - val_loss: 0.6269\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1243 - val_loss: 0.6384\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1218 - val_loss: 0.6430\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1192 - val_loss: 0.6496\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1171 - val_loss: 0.6514\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1150 - val_loss: 0.6588\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1127 - val_loss: 0.6651\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1111 - val_loss: 0.6716\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1086 - val_loss: 0.6762\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1066 - val_loss: 0.6871\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1048 - val_loss: 0.6876\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1025 - val_loss: 0.6935\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.1010 - val_loss: 0.6968\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0990 - val_loss: 0.6908\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0976 - val_loss: 0.7068\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0955 - val_loss: 0.7180\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0941 - val_loss: 0.7099\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0925 - val_loss: 0.7179\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0908 - val_loss: 0.7340\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0893 - val_loss: 0.7304\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0878 - val_loss: 0.7407\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0864 - val_loss: 0.7342\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0849 - val_loss: 0.7362\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0833 - val_loss: 0.7513\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0821 - val_loss: 0.7486\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0808 - val_loss: 0.7562\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0795 - val_loss: 0.7548\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0783 - val_loss: 0.7615\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0770 - val_loss: 0.7656\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0761 - val_loss: 0.7695\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0747 - val_loss: 0.7805\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0734 - val_loss: 0.7839\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0721 - val_loss: 0.7840\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0712 - val_loss: 0.7902\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0699 - val_loss: 0.7919\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0692 - val_loss: 0.7948\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0680 - val_loss: 0.8058\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0674 - val_loss: 0.8020\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0659 - val_loss: 0.8014\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0652 - val_loss: 0.8154\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0641 - val_loss: 0.8110\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0632 - val_loss: 0.8227\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.0624 - val_loss: 0.8233\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0616 - val_loss: 0.8287\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0608 - val_loss: 0.8399\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0600 - val_loss: 0.8303\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.0587 - val_loss: 0.8396\n"
     ]
    }
   ],
   "source": [
    "X, Y = vectorize_dataset(input_phrases, target_phrases,\n",
    "                  input_token_index,target_token_index,\n",
    "                  max_encoder_seq_length, max_decoder_seq_length)\n",
    "history = model.fit(X,Y,\n",
    "                   batch_size=batch_size, epochs=epochs, \n",
    "                   validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f460c67f0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-fd728d704aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_target_phrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_target_phrases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target_phrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "test_input_phrases = all_input_phrases[num_samples:num_samples+1000]\n",
    "test_target_phrases = all_target_phrases[num_samples:num_samples+1000]\n",
    "\n",
    "X, Y = vectorizer(test_input_phrases, test_target_phrases)\n",
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('training.h5')\n",
    "encoder_model.save('encoder.h5')\n",
    "decoder_model.save('decoder.h5')\n",
    "\n",
    "model_metadata = { 'input_token_index': input_token_index, \n",
    "                   'target_token_index': target_token_index,\n",
    "                   'max_encoder_seq_length': max_encoder_seq_length }\n",
    "\n",
    "with open('model_metadata.pickle', 'wb') as f:\n",
    "    pickle.dump(model_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('training.h5')\n",
    "encoder_model = load_model('encoder.h5')\n",
    "decoder_model = load_model('decoder.h5')\n",
    "\n",
    "with open('model_metadata.pickle', 'rb') as f:\n",
    "    model_metadata = pickle.load(f)\n",
    "\n",
    "input_token_index = model_metadata['input_token_index']\n",
    "target_token_index = model_metadata['target_token_index']\n",
    "max_encoder_seq_length = model_metadata['max_encoder_seq_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17376/280000 [>.............................] - ETA: 9:44"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-253576577d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.evaluate([encoder_input_data, decoder_input_data], \n\u001b[0;32m----> 2\u001b[0;31m                    decoder_target_data,)\n\u001b[0m",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.evaluate([encoder_input_data, decoder_input_data], \n",
    "                   decoder_target_data,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = {v: k for k, v in input_token_index.items()}\n",
    "reverse_target_char_index = {v: k for k, v in target_token_index.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decoder_inputs',\n",
       " 'decoder_input_h',\n",
       " 'decoder_input_c',\n",
       " 'decoder_lstm',\n",
       " 'decoder_dense']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l.name for l in decoder_model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'run!',\n",
       " 'run!',\n",
       " 'fire!',\n",
       " 'help!',\n",
       " 'jump',\n",
       " 'stop!',\n",
       " 'stop!',\n",
       " 'stop!',\n",
       " 'wait!',\n",
       " 'wait!',\n",
       " 'go on',\n",
       " 'go on',\n",
       " 'go on',\n",
       " 'i see',\n",
       " 'i try',\n",
       " 'i won!',\n",
       " 'i won!',\n",
       " 'oh no!',\n",
       " 'attack!',\n",
       " 'attack!',\n",
       " 'cheers!',\n",
       " 'cheers!',\n",
       " 'cheers!',\n",
       " 'cheers!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_phrases[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(phrase, encoder_model, decoder_model, \n",
    "              input_token_index, target_token_index):\n",
    "    vect = vectorize_phrase(phrase, input_token_index,\n",
    "                            max_encoder_seq_length)\n",
    "    decoded = decode_sequence(vect,target_token_index, \n",
    "                        encoder_model, decoder_model)\n",
    "    return decoded[:-1]\n",
    "\n",
    "translator = lambda p: translate(p, encoder_model, decoder_model,\n",
    "                                input_token_index, target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'va !'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_phrases, _ = read_data(data_path)\n",
    "input_phrases = text_preprocess(input_phrases)\n",
    "\n",
    "encoder_vectorizer = lambda b: vectorize_batch(b, input_token_index,\n",
    "                                               max_encoder_seq_length)\n",
    "decoder_vectorizer = lambda b, offset: vectorize_batch(b, target_token_index,\n",
    "                                                       max_decoder_seq_length, offset) \n",
    "\n",
    "def vectorized_gen(phrases, batch_size,encoder_vectorizer, decoder_vectorizer):\n",
    "    for i in range(0, len(phrases), batch_size):\n",
    "        input_phrases, target_phrases =  misspelling_gen(phrases[i:i+batch_size], 0.07, 3)\n",
    "        print(len(input_phrases))\n",
    "        print(len(target_phrases))\n",
    "        encoder_input_data = encoder_vectorizer(input_phrases)\n",
    "        decoder_input_data = decoder_vectorizer(target_phrases, False)\n",
    "        decoder_target_data = decoder_vectorizer(target_phrases, True)\n",
    "        max_encoder_seq_length = max([len(txt) for txt in input_phrases])\n",
    "        \n",
    "        yield ([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "        print('yielded')\n",
    "\n",
    "training_generator = vectorized_gen(input_phrases, num_samples, encoder_vectorizer, decoder_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_token_index = token_index(input_phrases)\n",
    "target_token_index = token_index(target_phrases)\n",
    "num_encoder_tokens = len(input_token_index)\n",
    "num_decoder_tokens = len(target_token_index)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_phrases])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_phrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000\n",
      "240000\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2888e8d3ee82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mspell_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmisspelling_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     model.fit(X, Y,\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9b10eacfd84f>\u001b[0m in \u001b[0;36mvectorized_gen\u001b[0;34m(phrases, batch_size, encoder_vectorizer, decoder_vectorizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_phrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_phrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mencoder_input_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_phrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdecoder_input_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdecoder_target_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9b10eacfd84f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m encoder_vectorizer = lambda b: vectorize_batch(b, input_token_index,\n\u001b[0;32m----> 5\u001b[0;31m                                                max_encoder_seq_length)\n\u001b[0m\u001b[1;32m      6\u001b[0m decoder_vectorizer = lambda b, offset: vectorize_batch(b, target_token_index,\n\u001b[1;32m      7\u001b[0m                                                        max_decoder_seq_length, offset) \n",
      "\u001b[0;32m<ipython-input-7-dd12a401fd16>\u001b[0m in \u001b[0;36mvectorize_batch\u001b[0;34m(texts, token_index, max_seq_len, offset)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Generate 1-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    spell_gen = lambda : misspelling_gen(input_phrases, 0.07, 3)\n",
    "    X, Y = next(training_generator)\n",
    "    model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
