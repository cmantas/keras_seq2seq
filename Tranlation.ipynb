{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# ignore some Keras warnings regarding deprecations and model saving \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import pickle, numpy as np\n",
    "from random import Random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 2  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples =5000 # Number of samples to train on.\n",
    "# Path to the datatxt file on disk.\n",
    "data_path = 'fra.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fname, delimiter=\"\\n\"):\n",
    "    \"\"\"Helper reading a file with the input and \n",
    "    target texts.\n",
    "    Returns a tuple with 2 lists of phrases (input, target)\"\"\"\n",
    "    input_phrases = []\n",
    "    target_phrases = []\n",
    "    with open(fname, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split(delimiter)\n",
    "    \n",
    "        for line in lines:\n",
    "            pair = line.split('\\t')\n",
    "            if len(pair) !=2: continue \n",
    "\n",
    "            input_text, target_text = pair\n",
    "            input_phrases.append(input_text)\n",
    "            target_phrases.append(target_text)\n",
    "\n",
    "        return (input_phrases, target_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrap_with_delims(texts, start='\\t', end='\\n'):\n",
    "    \"\"\"Helper wrapping the input texts with the start\n",
    "    and and end sequence delimiters.\"\"\" \n",
    "    return [start + t + end for t in texts]\n",
    "\n",
    "def text_preprocess(texts):\n",
    "    \"\"\"Some minimal text preprocessing:\n",
    "    * downcase\n",
    "    * remove trailing periods\n",
    "    * remove a weird unicode char\"\"\"\n",
    "    return [t.strip().lower().\\\n",
    "            rstrip('.').strip().\\\n",
    "            replace(u'\\u202f', '').\\\n",
    "            replace(u'\\ufeff','') for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 5000 selected phrases\n"
     ]
    }
   ],
   "source": [
    "all_input_phrases, all_target_phrases = read_data(data_path)\n",
    "all_input_phrases = text_preprocess(all_input_phrases)\n",
    "all_target_phrases = text_preprocess(all_target_phrases)\n",
    "all_target_phrases = wrap_with_delims(all_target_phrases)\n",
    "\n",
    "# keep only `num_samples` examples. \n",
    "# Note: we're starting from the 2nd example, its not important\n",
    "input_phrases, target_phrases = all_input_phrases[1:num_samples+1], all_target_phrases[1:num_samples+1]\n",
    "# Wrap the target phrases with delimiters signifying the start end end of the sequence\n",
    "\n",
    "print(\"Training on %d selected phrases\" % len(input_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('run!', '\\tcours!\\n'),\n",
       " ('run!', '\\tcourez!\\n'),\n",
       " ('wow!', '\\tça alors!\\n'),\n",
       " ('fire!', '\\tau feu !\\n'),\n",
       " ('help!', \"\\tà l'aide!\\n\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(input_phrases[:5], target_phrases[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5}\n"
     ]
    }
   ],
   "source": [
    "# a dict of the index of each token\n",
    "def token_index(texts):\n",
    "    \"\"\"Create a dictionary with all characters in the `texts` corpus\n",
    "    and a number signifying their index in an 1-hot encoding.\"\"\"\n",
    "    vocab = set()\n",
    "    for txt in texts:\n",
    "        for char in txt: vocab.add(char)\n",
    "    vocab = sorted(list(vocab))\n",
    "    return dict([(char, i) for i, char in enumerate(vocab)])\n",
    "print(token_index(['abc', 'cde!']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique input tokens: 63\n",
      "Number of unique output tokens: 83\n",
      "Max sequence length for inputs: 14\n",
      "Max sequence length for outputs: 58\n"
     ]
    }
   ],
   "source": [
    "# build the token index on all available phrases\n",
    "input_token_index = token_index(all_input_phrases)\n",
    "target_token_index = token_index(all_target_phrases)\n",
    "num_encoder_tokens = len(input_token_index)\n",
    "num_decoder_tokens = len(target_token_index)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_phrases])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_phrases])\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_batch(texts, token_index, max_seq_len, offset=False):\n",
    "    num_tokens = len(token_index)\n",
    "    example_count =len(texts)\n",
    "    \n",
    "    # Generate 1-hot encoding\n",
    "    data = np.zeros((example_count, max_seq_len, num_tokens),dtype='float32')\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        start_t = 1 if offset else 0\n",
    "        for t, char in enumerate(text[start_t:]):\n",
    "            idx = token_index[char]\n",
    "            data[i, t, idx] = 1.\n",
    "    return data\n",
    "\n",
    "def vectorize_dataset(input_texts, target_texts,\n",
    "                      input_token_index, target_token_index,\n",
    "                      max_encoder_seq_length, max_decoder_seq_length):\n",
    "    return ([vectorize_batch(input_texts, input_token_index,\n",
    "                             max_encoder_seq_length),\n",
    "             vectorize_batch(target_texts, target_token_index,\n",
    "                             max_decoder_seq_length)],\n",
    "            # same as decoder input data, but offset by one\n",
    "            vectorize_batch(target_texts, target_token_index,\n",
    "                            max_decoder_seq_length, True))\n",
    "\n",
    "def vectorizer(inp, targ):\n",
    "    \"\"\"A closure that encapsulates the information about the token indices and\n",
    "    the sequence lengths\"\"\"\n",
    "    return vectorize_dataset(inp, targ, input_token_index,\n",
    "                             target_token_index,\n",
    "                             max_encoder_seq_length, \n",
    "                             max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def models(num_encoder_tokens, num_decoder_tokens, latent_dim):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_inputs')\n",
    "    encoder = LSTM(latent_dim, return_state=True, name='encoder')\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_inputs')\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, \n",
    "                        name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax', \n",
    "                          name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # Next: inference mode (sampling).\n",
    "    # Here's the drill:\n",
    "    # 1) encode input and retrieve initial decoder state\n",
    "    # 2) run one step of decoder with this initial state\n",
    "    # and a \"start of sequence\" token as target.\n",
    "    # Output will be the next target token\n",
    "    # 3) Repeat with the current target token and current states\n",
    "\n",
    "    # Define sampling models\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,), name='decoder_input_h')\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,), name='decoder_input_c')\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, encoder_model, decoder_model = models(num_encoder_tokens, num_decoder_tokens, latent_dim)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/2\n",
      "4500/4500 [==============================] - 28s 6ms/step - loss: 0.8842 - val_loss: 0.9229\n",
      "Epoch 2/2\n",
      "4500/4500 [==============================] - 31s 7ms/step - loss: 0.7886 - val_loss: 0.7996\n"
     ]
    }
   ],
   "source": [
    "#X = [encoder_input_data, decoder_input_data]\n",
    "#Y = decoder_target_data\n",
    "X, Y = vectorizer(input_phrases, target_phrases)\n",
    "history = model.fit(X,Y,\n",
    "                   batch_size=batch_size, epochs=epochs, \n",
    "                   validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_history(history):\n",
    "    \"\"\"credit: https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\"\"\"\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9903ef588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input_phrases = all_input_phrases[num_samples:num_samples+1000]\n",
    "test_target_phrases = all_target_phrases[num_samples:num_samples+1000]\n",
    "\n",
    "X, Y = vectorizer(test_input_phrases, test_target_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 12s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7571103242874145"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('training.h5')\n",
    "encoder_model.save('encoder.h5')\n",
    "decoder_model.save('decoder.h5')\n",
    "\n",
    "model_metadata = { 'input_token_index': input_token_index, \n",
    "                   'target_token_index': target_token_index,\n",
    "                   'max_encoder_seq_length': max_encoder_seq_length }\n",
    "\n",
    "with open('model_metadata.pickle', 'wb') as f:\n",
    "    pickle.dump(model_metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('training.h5')\n",
    "encoder_model = load_model('encoder.h5')\n",
    "decoder_model = load_model('decoder.h5')\n",
    "\n",
    "with open('model_metadata.pickle', 'rb') as f:\n",
    "    model_metadata = pickle.load(f)\n",
    "\n",
    "input_token_index = model_metadata['input_token_index']\n",
    "target_token_index = model_metadata['target_token_index']\n",
    "max_encoder_seq_length = model_metadata['max_encoder_seq_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17376/280000 [>.............................] - ETA: 9:44"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-253576577d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.evaluate([encoder_input_data, decoder_input_data], \n\u001b[0;32m----> 2\u001b[0;31m                    decoder_target_data,)\n\u001b[0m",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                                          steps=steps)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cmantas/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.evaluate([encoder_input_data, decoder_input_data], \n",
    "                   decoder_target_data,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = {v: k for k, v in input_token_index.items()}\n",
    "reverse_target_char_index = {v: k for k, v in target_token_index.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decoder_inputs',\n",
       " 'decoder_input_h',\n",
       " 'decoder_input_c',\n",
       " 'decoder_lstm',\n",
       " 'decoder_dense']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l.name for l in decoder_model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['run!',\n",
       " 'run!',\n",
       " 'wow!',\n",
       " 'fire!',\n",
       " 'help!',\n",
       " 'jump',\n",
       " 'stop!',\n",
       " 'stop!',\n",
       " 'stop!',\n",
       " 'wait!',\n",
       " 'wait!',\n",
       " 'i see',\n",
       " 'i try',\n",
       " 'i won!',\n",
       " 'i won!',\n",
       " 'oh no!',\n",
       " 'attack!',\n",
       " 'attack!',\n",
       " 'cheers!',\n",
       " 'cheers!',\n",
       " 'cheers!',\n",
       " 'cheers!',\n",
       " 'get up',\n",
       " 'got it!',\n",
       " 'got it!']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_phrases[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(phrase, encoder_model, decoder_model, \n",
    "              input_token_index, target_token_index):\n",
    "    vect = vectorize_phrase(phrase, input_token_index,\n",
    "                            max_encoder_seq_length)\n",
    "    decoded = decode_sequence(vect,target_token_index, \n",
    "                        encoder_model, decoder_model)\n",
    "    return decoded[:-1]\n",
    "\n",
    "translator = lambda p: translate(p, encoder_model, decoder_model,\n",
    "                                input_token_index, target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire out',\n",
       " 'stop',\n",
       " 'come in',\n",
       " 'get out',\n",
       " 'i can go',\n",
       " \"i'm sor\",\n",
       " 'he is busy',\n",
       " \"he's drunk\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find max encoder seq legth\n",
    "#max_encoder_seq_length = encoder_model.get_layer('encoder_inputs').input_shape[-1]\n",
    "phrases = ['fire', 'stp', 'comein', 'get ot', 'i cant go',\n",
    "          'im sorry', 'h is busi', 'hes drunk']\n",
    "\n",
    "[translator(phrase) for phrase in phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.232"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrases = input_phrases[20:1020]\n",
    "misspelled_test_phrases = [add_noise_to_string(p, .1) for p in test_phrases]\n",
    "\n",
    "pairs = zip(misspelled_test_phrases, test_phrases)\n",
    "errors = list(filter(lambda p: translator(p[0]) != p[1], pairs))\n",
    "len(errors)/float(len(test_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_phrases, _ = read_data(data_path)\n",
    "input_phrases = text_preprocess(input_phrases)\n",
    "\n",
    "encoder_vectorizer = lambda b: vectorize_batch(b, input_token_index,\n",
    "                                               max_encoder_seq_length)\n",
    "decoder_vectorizer = lambda b, offset: vectorize_batch(b, target_token_index,\n",
    "                                                       max_decoder_seq_length, offset) \n",
    "\n",
    "def vectorized_gen(phrases, batch_size,encoder_vectorizer, decoder_vectorizer):\n",
    "    for i in range(0, len(phrases), batch_size):\n",
    "        input_phrases, target_phrases =  misspelling_gen(phrases[i:i+batch_size], 0.07, 3)\n",
    "        print(len(input_phrases))\n",
    "        print(len(target_phrases))\n",
    "        encoder_input_data = encoder_vectorizer(input_phrases)\n",
    "        decoder_input_data = decoder_vectorizer(target_phrases, False)\n",
    "        decoder_target_data = decoder_vectorizer(target_phrases, True)\n",
    "        max_encoder_seq_length = max([len(txt) for txt in input_phrases])\n",
    "        \n",
    "        yield ([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "        print('yielded')\n",
    "\n",
    "training_generator = vectorized_gen(input_phrases, num_samples, encoder_vectorizer, decoder_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_token_index = token_index(input_phrases)\n",
    "target_token_index = token_index(target_phrases)\n",
    "num_encoder_tokens = len(input_token_index)\n",
    "num_decoder_tokens = len(target_token_index)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_phrases])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_phrases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000\n",
      "240000\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2888e8d3ee82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mspell_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmisspelling_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.07\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     model.fit(X, Y,\n\u001b[1;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9b10eacfd84f>\u001b[0m in \u001b[0;36mvectorized_gen\u001b[0;34m(phrases, batch_size, encoder_vectorizer, decoder_vectorizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_phrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_phrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mencoder_input_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_phrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdecoder_input_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdecoder_target_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9b10eacfd84f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m encoder_vectorizer = lambda b: vectorize_batch(b, input_token_index,\n\u001b[0;32m----> 5\u001b[0;31m                                                max_encoder_seq_length)\n\u001b[0m\u001b[1;32m      6\u001b[0m decoder_vectorizer = lambda b, offset: vectorize_batch(b, target_token_index,\n\u001b[1;32m      7\u001b[0m                                                        max_decoder_seq_length, offset) \n",
      "\u001b[0;32m<ipython-input-7-dd12a401fd16>\u001b[0m in \u001b[0;36mvectorize_batch\u001b[0;34m(texts, token_index, max_seq_len, offset)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Generate 1-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    spell_gen = lambda : misspelling_gen(input_phrases, 0.07, 3)\n",
    "    X, Y = next(training_generator)\n",
    "    model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
